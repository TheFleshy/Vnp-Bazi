{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a6df68-4304-4651-8db9-eb3ce9f47002",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "74b63ce98cf2efada80913b337a0b26a",
     "grade": false,
     "grade_id": "cell-a8975f224683d303",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 3 A: Neural Network for Customer Churn Prediction\n",
    "\n",
    "**Dataset:** `churn.csv`  \n",
    "**Goal:** Predict whether a bank customer will leave the bank (`Exited = 1`) using a neural network classifier.\n",
    "\n",
    "You will implement the following pieces:\n",
    "\n",
    "1. `prepare_data(df)` – preprocessing, encoding, scaling, train/validation split  \n",
    "2. `ChurnDataset` – custom PyTorch Dataset  \n",
    "3. `build_model(input_dim)` – neural network classifier  \n",
    "4. `train_one_epoch(model, train_loader, criterion, optimizer)` – train loop for one epoch  \n",
    "5. `evaluate(model, val_loader)` – compute validation accuracy\n",
    "\n",
    "All these will be **autograded** with nbgrader.\n",
    "\n",
    "**Important:**  \n",
    "- Do not change function names or their parameters.  \n",
    "- Do not change the return types.  \n",
    "- Do not remove or rename variables used in the templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4695db52-b8ce-44a6-ab34-cef1d361d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24f5f29-234b-4df8-b714-e33b058580e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fb1e9c1aa1701c80dc079d2a3d2990b",
     "grade": false,
     "grade_id": "cell-7ac3b784e00c6873",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>421</td>\n",
       "      <td>15810418</td>\n",
       "      <td>T'ang</td>\n",
       "      <td>756</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>115924.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93524.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RowNumber  CustomerId Surname  CreditScore Geography  Gender  Age  \\\n",
       "420        421    15810418   T'ang          756   Germany  Female   60   \n",
       "\n",
       "     Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "420       3  115924.89              1          1               0   \n",
       "\n",
       "     EstimatedSalary  Exited  \n",
       "420         93524.19       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e38741-ea76-459b-999c-d6ee21683283",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87b47100496f72118cb7a2f6bcc80c2d",
     "grade": false,
     "grade_id": "cell-e5e8fa4957f851da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def prepare_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prepare the churn data for a neural network.\n",
    "\n",
    "    Steps (you MUST follow these steps):\n",
    "    1. Drop the columns: \"RowNumber\", \"CustomerId\", \"Surname\"\n",
    "    2. Separate features (X) and target (y), where target is \"Exited\"\n",
    "    3. Use ColumnTransformer with OneHotEncoder to encode:\n",
    "       - categorical columns: [\"Geography\", \"Gender\"]\n",
    "       - use OneHotEncoder(drop=\"first\", sparse_output=False) \n",
    "         (if sparse_output doesn't exist in your sklearn, use sparse=False instead)\n",
    "    4. Apply the transformer to X to get a numeric numpy array\n",
    "    5. Apply StandardScaler to ALL resulting features\n",
    "    6. Split into train and validation sets using:\n",
    "         - test_size=0.2\n",
    "         - random_state=42\n",
    "         - stratify=y\n",
    "    7. Return:\n",
    "         X_train, X_val, y_train, y_val, preprocessor, scaler\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    df = df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"])\n",
    "    X = df.drop(columns=[\"Exited\"])\n",
    "    y = df[\"Exited\"]\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"encoder\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"Geography\", \"Gender\"])\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_transformed)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "    return X_train, X_val, y_train, y_val, preprocessor, scaler\n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6dbf65c-a1b7-4946-a37e-00c85f1de6fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b25ee685a458cfec6f68f8bd176bc9e",
     "grade": false,
     "grade_id": "cell-9a766f20ca96bdd8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11), (8000,), (2000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, preprocessor, scaler = prepare_data(df)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb9f346c-ee8b-4a2e-9606-868271f62503",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b7b16b4767c9c55a0e43d89dfebd562",
     "grade": false,
     "grade_id": "cell-ecfdf5f78531cf30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "class ChurnDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for the churn data.\n",
    "\n",
    "    - __init__(self, X, y):\n",
    "        * X: numpy array of features\n",
    "        * y: array-like of labels (0 or 1)\n",
    "        * store them as tensors:\n",
    "             - X as float32\n",
    "             - y as float32 with shape (N, 1)\n",
    "    - __len__(self): returns number of samples\n",
    "    - __getitem__(self, idx): returns (X[idx], y[idx])\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        # convert to tensors\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0935bcf0-dd1e-4a6c-826f-9eb2ff2a403a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e58f3e54f9fe3a43ef7f5843ee986ed7",
     "grade": false,
     "grade_id": "cell-8c8cace319f55504",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ChurnDataset(X_train, y_train)\n",
    "val_ds = ChurnDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf5f6b35-5400-49db-9907-6b3cc66ef9bb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e23500500ce9826bdc73b3efd8db8e09",
     "grade": false,
     "grade_id": "cell-181afdc2ba9cd7b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def build_model(input_dim: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Build and return a PyTorch neural network for binary classification.\n",
    "\n",
    "    Requirements:\n",
    "    - Use nn.Sequential\n",
    "    - Architecture suggestion (you may use exactly this):\n",
    "        Linear(input_dim, 32) -> ReLU\n",
    "        Linear(32, 16) -> ReLU\n",
    "        Linear(16, 1) -> Sigmoid\n",
    "    - The final layer MUST have 1 neuron with Sigmoid activation (output in [0,1]).\n",
    "    \"\"\"\n",
    "    model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    return model\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "430cf54d-332f-46a6-96b2-22dbf669ec03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed785c481f239f2c4184fcea59777be6",
     "grade": false,
     "grade_id": "cell-3ad3be096655ce8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=11, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = build_model(input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6cd6419-952b-4ca6-afaf-a5d2507a8d9f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "537655578de706aae3452bde122e3629",
     "grade": false,
     "grade_id": "cell-465cd262f06130d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def train_one_epoch(model: nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    criterion,\n",
    "                    optimizer) -> float:\n",
    "    \"\"\"\n",
    "    Train the model for ONE epoch on the training data.\n",
    "\n",
    "    Requirements:\n",
    "    - Set model to train mode: model.train()\n",
    "    - Loop over batches from train_loader\n",
    "      * Compute predictions\n",
    "      * Compute loss\n",
    "      * Zero the gradients\n",
    "      * Backpropagate\n",
    "      * Step the optimizer\n",
    "      * Accumulate the loss (sum)\n",
    "    - Return the average training loss as a float \n",
    "      (total loss divided by number of batches)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(xb)\n",
    "        \n",
    "        loss = criterion(outputs, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06ed77ec-4437-454e-816a-376d6e23684f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e22bce6b0d781b368a6246b8ef3e5393",
     "grade": false,
     "grade_id": "cell-6c98cdf3410069e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def evaluate(model: nn.Module, val_loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation data.\n",
    "\n",
    "    Requirements:\n",
    "    - Set the model to eval mode: model.eval()\n",
    "    - Disable gradients using torch.no_grad()\n",
    "    - Loop over batches from val_loader:\n",
    "        * Compute predictions\n",
    "        * Convert predictions to labels using threshold 0.5\n",
    "        * Collect all true labels and predicted labels\n",
    "    - Return the accuracy on the full validation set as a float in [0, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(torch.tensor(X_test, dtype=torch.float32)).numpy().flatten()\n",
    "\n",
    "    y_pred[0:10]\n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "854e2b8b-9d2d-464b-b856-6dc7b1a63f0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa502c5b1f64e3f045b3f7d6088659ca",
     "grade": false,
     "grade_id": "cell-7df12924db8be329",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60, loss = 0.3401\n",
      "Epoch 20/60, loss = 0.3306\n",
      "Epoch 30/60, loss = 0.3240\n",
      "Epoch 40/60, loss = 0.3185\n",
      "Epoch 50/60, loss = 0.3144\n",
      "Epoch 60/60, loss = 0.3112\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      6\u001b[39m     train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     val_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     train_losses.append(train_loss)\n\u001b[32m     10\u001b[39m     val_accuracies.append(val_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, val_loader)\u001b[39m\n\u001b[32m     18\u001b[39m model.eval()\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     y_pred = model(torch.tensor(\u001b[43mX_test\u001b[49m, dtype=torch.float32)).numpy().flatten()\n\u001b[32m     22\u001b[39m y_pred[\u001b[32m0\u001b[39m:\u001b[32m10\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train loss: {train_loss:.4f} | Val acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680dc95-934f-4327-a4e1-eefa421fba11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8fb826e1278085994e5914c9ae675a8c",
     "grade": false,
     "grade_id": "cell-845f2660ecd3cb2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_accuracies)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd23ac0-5b22-4bf7-8479-6a76430ec888",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8df77745a036a40f9b37f95f583eb367",
     "grade": false,
     "grade_id": "cell-3bd1f60db17071f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Answer\n",
    "\n",
    "1. What validation accuracy did you reach?\n",
    "2. Does the model appear to overfit or underfit?\n",
    "3. Name one way to potentially improve performance (architecture or preprocessing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3301d88-9056-4352-a104-3ec46891f9cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1690f283c5c2ea3c175642dcc2b765af",
     "grade": false,
     "grade_id": "cell-ea74e12d4b7b4da2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Run the tests to verify your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf29221-b86f-43c1-bf95-348ab9fcdec4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "46211a1ce980c02177076b0a7c636574",
     "grade": false,
     "grade_id": "cell-977ce02d414c598e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def hash_data_frame(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Compute a stable hash for a DataFrame by:\n",
    "    - sorting columns\n",
    "    - sorting rows by all columns\n",
    "    - hashing the underlying values\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_index(axis=1).sort_values(by=list(df.columns))\n",
    "    return hashlib.sha256(pd.util.hash_pandas_object(df_sorted, index=True).values).hexdigest()\n",
    "\n",
    "def hash_series(series: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Compute a stable hash for a Series by:\n",
    "    - converting values to string\n",
    "    - joining with commas\n",
    "    - hashing the resulting string\n",
    "    \"\"\"\n",
    "    series_str = \",\".join(map(str, series.values))\n",
    "    return hashlib.sha256(series_str.encode()).hexdigest()\n",
    "\n",
    "def check_signature(expected: str, actual: str):\n",
    "    try:\n",
    "        assert actual == expected\n",
    "        print(\"✔ Test passed!\")\n",
    "    except AssertionError:\n",
    "        print(\"✘ Test failed.\")\n",
    "        raise\n",
    "\n",
    "def test_prepare_data(func, sig_X_train, sig_X_val, sig_y_train, sig_y_val):\n",
    "    \"\"\"\n",
    "    Wrapper for testing the student's `prepare_data(df)` function using hashes.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"churn.csv\")\n",
    "    X_train, X_val, y_train, y_val, preprocessor, scaler = func(df)\n",
    "\n",
    "    # Convert to DataFrame / Series for hashing\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_val_df = pd.DataFrame(X_val)\n",
    "    y_train_s = pd.Series(y_train).reset_index(drop=True)\n",
    "    y_val_s = pd.Series(y_val).reset_index(drop=True)\n",
    "\n",
    "    # Basic sanity\n",
    "    assert X_train_df.shape[0] > 0\n",
    "    assert X_val_df.shape[0] > 0\n",
    "    assert X_train_df.shape[1] == X_val_df.shape[1]\n",
    "\n",
    "    # Hashes\n",
    "    h_Xtr = hash_data_frame(X_train_df)\n",
    "    h_Xv  = hash_data_frame(X_val_df)\n",
    "    h_ytr = hash_series(y_train_s)\n",
    "    h_yv  = hash_series(y_val_s)\n",
    "\n",
    "    try:\n",
    "        assert h_Xtr == sig_X_train\n",
    "        assert h_Xv  == sig_X_val\n",
    "        assert h_ytr == sig_y_train\n",
    "        assert h_yv  == sig_y_val\n",
    "        print(\"✔ Test passed!\")\n",
    "    except AssertionError:\n",
    "        print(\"✘ Test failed (signatures do not match).\")\n",
    "        # Uncomment while generating signatures:\n",
    "        # print(\"DEBUG:\", h_Xtr, h_Xv, h_ytr, h_yv)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78fc7c-d34b-486e-82a8-23ea53c32e9b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f99eec3ad1d17bea800ff27dd99f062",
     "grade": true,
     "grade_id": "cell-c68ba70b500bc5bb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST\n",
    "SIG_X_TRAIN = \"5c50238ec85cb41c11b0eabc4be851c56a41aa367bc3945dcfc07e83a5e8e079\"\n",
    "SIG_X_VAL   = \"4ef850e8dea3a9f462535f178165dc02b06a1f5e31ac9d364d779b291407d33a\"\n",
    "SIG_Y_TRAIN = \"9b8c6fff66645ef6ca27fb516a51c4c9d2645710f2809c05887d98fa938e93e4\"\n",
    "SIG_Y_VAL   = \"516080ad1fc8e2349df09a1de08ffb3fc50d7ff7a36c5f4f82af08b8ef55f783\"\n",
    "\n",
    "test_prepare_data(\n",
    "    prepare_data,\n",
    "    SIG_X_TRAIN,\n",
    "    SIG_X_VAL,\n",
    "    SIG_Y_TRAIN,\n",
    "    SIG_Y_VAL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c208fd-8bbc-4d41-aa32-3570354f9c5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ca0af4dfb26df22aa681cb90830748da",
     "grade": true,
     "grade_id": "cell-ef46da143678a2a4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST \n",
    "train_ds = ChurnDataset(X_train, y_train)\n",
    "\n",
    "# basic length\n",
    "assert len(train_ds) == X_train.shape[0]\n",
    "\n",
    "# sample item\n",
    "x0, y0 = train_ds[0]\n",
    "assert isinstance(x0, torch.Tensor)\n",
    "assert isinstance(y0, torch.Tensor)\n",
    "assert x0.shape[0] == X_train.shape[1]\n",
    "assert y0.shape == (1,)\n",
    "assert x0.dtype == torch.float32\n",
    "assert y0.dtype == torch.float32\n",
    "\n",
    "print(\"✔ Test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a3bc1-1429-4b33-a045-e65d1f8c21e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a26f14265465123e246f163782028c4d",
     "grade": true,
     "grade_id": "cell-fa177f8aeccde60b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST \n",
    "input_dim = X_train.shape[1]\n",
    "model_test = build_model(input_dim)\n",
    "\n",
    "assert isinstance(model_test, torch.nn.Module)\n",
    "\n",
    "dummy = torch.randn(4, input_dim)\n",
    "out = model_test(dummy)\n",
    "\n",
    "# output shape and range\n",
    "assert out.shape == (4, 1)\n",
    "assert torch.all(out >= 0.0)\n",
    "assert torch.all(out <= 1.0)\n",
    "\n",
    "print(\"✔ Test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268c2ba-c12b-4e41-b7b3-aa8f7a52a9cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "adcd275f3d23dd95971cbedf3abd0c60",
     "grade": true,
     "grade_id": "cell-b4c36ea14747f756",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST \n",
    "train_loader_test = DataLoader(ChurnDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "\n",
    "model_te = build_model(X_train.shape[1])\n",
    "criterion_te = torch.nn.BCELoss()\n",
    "optimizer_te = torch.optim.Adam(model_te.parameters(), lr=0.001)\n",
    "\n",
    "loss1 = train_one_epoch(model_te, train_loader_test, criterion_te, optimizer_te)\n",
    "\n",
    "assert isinstance(loss1, float)\n",
    "assert 0.0 < loss1 < 10.0   # loose bounds\n",
    "\n",
    "print(\"✔ Test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0c611-821c-4e11-ae5d-c6152ee743cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "246540bb34d416ceb8d094ab5836334d",
     "grade": true,
     "grade_id": "cell-21619f0c9fea10bc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST \n",
    "val_loader_test = DataLoader(ChurnDataset(X_val, y_val), batch_size=256, shuffle=False)\n",
    "\n",
    "acc_val = evaluate(model_te, val_loader_test)\n",
    "\n",
    "assert isinstance(acc_val, float)\n",
    "assert 0.0 <= acc_val <= 1.0\n",
    "\n",
    "print(\"✔ Test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736db25a-d697-4c50-a51b-fcbe9ba53f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnp-24-25",
   "language": "python",
   "name": "vnp-24-25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
